{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0cef5d",
   "metadata": {},
   "source": [
    "Import libraries and load the hugging face token from the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f932b8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import huggingface_hub\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import paraphrase_mining\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47125e0e",
   "metadata": {},
   "source": [
    "Log in to hugging face and download and initialize the model. It automatically caches it, so it won't re-download unless it doesn't find it in the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10e60cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "huggingface_hub.login(token=os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b297fe",
   "metadata": {},
   "source": [
    "Compute embeddings and similarities. Can also use `util.dot_score` but `model.similarity` does the same thing. actually worth noting that `model.similarity` uses cosine similarity by default, not dot product, though it can use different functions:\n",
    "> The similarity metric that is used is stored in the SentenceTransformer instance under SentenceTransformer.similarity_fn_name. Valid options are:\n",
    ">\n",
    "> - SimilarityFunction.COSINE (a.k.a “cosine”): Cosine Similarity (default)\n",
    "> - SimilarityFunction.DOT_PRODUCT (a.k.a “dot”): Dot Product\n",
    "> - SimilarityFunction.EUCLIDEAN (a.k.a “euclidean”): Negative Euclidean Distance\n",
    "> - SimilarityFunction.MANHATTAN (a.k.a. “manhattan”): Negative Manhattan Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1be0bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tall similarities to:\n",
      "tall: 1.0\n",
      "short: 0.6037872433662415\n",
      "towering: 0.7457533478736877\n",
      "tiny: 0.57103431224823\n",
      "baseball: 0.5436896681785583\n",
      "basketball: 0.6031945943832397\n",
      "cat poster: 0.3962147831916809\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"tall\",\n",
    "    \"short\",\n",
    "    \"towering\",\n",
    "    \"tiny\",\n",
    "    \"baseball\",\n",
    "    \"basketball\",\n",
    "    \"cat poster\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings[0], embeddings)\n",
    "print(f\"{sentences[0]} similarities to:\")\n",
    "\n",
    "for index, score in enumerate(similarities[0]):\n",
    "    print(f\"{sentences[index]}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2fdfb",
   "metadata": {},
   "source": [
    "try comparing them all to each other and making it a pandas dataframe for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694a79df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tall</th>\n",
       "      <th>short</th>\n",
       "      <th>towering</th>\n",
       "      <th>tiny</th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>cat poster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603787</td>\n",
       "      <td>0.745753</td>\n",
       "      <td>0.571034</td>\n",
       "      <td>0.543690</td>\n",
       "      <td>0.603195</td>\n",
       "      <td>0.396215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>0.603787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514112</td>\n",
       "      <td>0.591454</td>\n",
       "      <td>0.546970</td>\n",
       "      <td>0.586990</td>\n",
       "      <td>0.352861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>towering</th>\n",
       "      <td>0.745753</td>\n",
       "      <td>0.514112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556181</td>\n",
       "      <td>0.539553</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>0.421939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>0.571034</td>\n",
       "      <td>0.591454</td>\n",
       "      <td>0.556181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.524438</td>\n",
       "      <td>0.535622</td>\n",
       "      <td>0.414646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>0.543690</td>\n",
       "      <td>0.546970</td>\n",
       "      <td>0.539553</td>\n",
       "      <td>0.524438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776411</td>\n",
       "      <td>0.435858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basketball</th>\n",
       "      <td>0.603195</td>\n",
       "      <td>0.586990</td>\n",
       "      <td>0.562235</td>\n",
       "      <td>0.535622</td>\n",
       "      <td>0.776411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat poster</th>\n",
       "      <td>0.396215</td>\n",
       "      <td>0.352861</td>\n",
       "      <td>0.421939</td>\n",
       "      <td>0.414646</td>\n",
       "      <td>0.435858</td>\n",
       "      <td>0.463468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tall     short  towering      tiny  baseball  basketball  \\\n",
       "tall        1.000000  0.603787  0.745753  0.571034  0.543690    0.603195   \n",
       "short       0.603787  1.000000  0.514112  0.591454  0.546970    0.586990   \n",
       "towering    0.745753  0.514112  1.000000  0.556181  0.539553    0.562235   \n",
       "tiny        0.571034  0.591454  0.556181  1.000000  0.524438    0.535622   \n",
       "baseball    0.543690  0.546970  0.539553  0.524438  1.000000    0.776411   \n",
       "basketball  0.603195  0.586990  0.562235  0.535622  0.776411    1.000000   \n",
       "cat poster  0.396215  0.352861  0.421939  0.414646  0.435858    0.463468   \n",
       "\n",
       "            cat poster  \n",
       "tall          0.396215  \n",
       "short         0.352861  \n",
       "towering      0.421939  \n",
       "tiny          0.414646  \n",
       "baseball      0.435858  \n",
       "basketball    0.463468  \n",
       "cat poster    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"tall\",\n",
    "    \"short\",\n",
    "    \"towering\",\n",
    "    \"tiny\",\n",
    "    \"baseball\",\n",
    "    \"basketball\",\n",
    "    \"cat poster\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "\n",
    "df = pd.DataFrame(data=similarities, index=sentences, columns=sentences)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3ba34",
   "metadata": {},
   "source": [
    "Search for most similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5d3cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7764: baseball and basketball\n",
      "0.7564: bowl and cup\n",
      "0.7458: tall and towering\n",
      "0.7324: basketball and bowl\n",
      "0.7167: man and woman\n",
      "0.7067: baseball and bowl\n",
      "0.6700: basketball and cup\n",
      "0.6290: TV and bowl\n",
      "0.6254: basketball and TV\n",
      "0.6230: french and book\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"tall\",\n",
    "    \"short\",\n",
    "    \"towering\",\n",
    "    \"tiny\",\n",
    "    \"baseball\",\n",
    "    \"basketball\",\n",
    "    \"cat poster\",\n",
    "    \"friendship\",\n",
    "    \"man\",\n",
    "    \"woman\",\n",
    "    \"french\",\n",
    "    \"tissue\",\n",
    "    \"TV\",\n",
    "    \"book\",\n",
    "    \"bowl\",\n",
    "    \"remote\",\n",
    "    \"cup\",\n",
    "]\n",
    "\n",
    "paraphrases = paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[:10]:\n",
    "    score, i, j = paraphrase\n",
    "    print(f\"{score:.4f}: {sentences[i]} and {sentences[j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cf698",
   "metadata": {},
   "source": [
    "Retrieve the tokenizer vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be49e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model[0].tokenizer\n",
    "vocab = list(tokenizer.get_vocab().keys())\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e45e8c",
   "metadata": {},
   "source": [
    "How does it handle spelling variants? ...turns out it handles them well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b5144f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>centre</th>\n",
       "      <th>acknowledgement</th>\n",
       "      <th>acknowledgment</th>\n",
       "      <th>aluminium</th>\n",
       "      <th>aluminum</th>\n",
       "      <th>apologise</th>\n",
       "      <th>apologize</th>\n",
       "      <th>armour</th>\n",
       "      <th>armor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965872</td>\n",
       "      <td>0.438927</td>\n",
       "      <td>0.432333</td>\n",
       "      <td>0.414315</td>\n",
       "      <td>0.432154</td>\n",
       "      <td>0.370660</td>\n",
       "      <td>0.387622</td>\n",
       "      <td>0.484073</td>\n",
       "      <td>0.525622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centre</th>\n",
       "      <td>0.965872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451336</td>\n",
       "      <td>0.435852</td>\n",
       "      <td>0.420350</td>\n",
       "      <td>0.423102</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.389248</td>\n",
       "      <td>0.487540</td>\n",
       "      <td>0.516287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledgement</th>\n",
       "      <td>0.438927</td>\n",
       "      <td>0.451336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986960</td>\n",
       "      <td>0.430719</td>\n",
       "      <td>0.432185</td>\n",
       "      <td>0.594707</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.498650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledgment</th>\n",
       "      <td>0.432333</td>\n",
       "      <td>0.435852</td>\n",
       "      <td>0.986960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428793</td>\n",
       "      <td>0.437130</td>\n",
       "      <td>0.570335</td>\n",
       "      <td>0.567112</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.495369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aluminium</th>\n",
       "      <td>0.414315</td>\n",
       "      <td>0.420350</td>\n",
       "      <td>0.430719</td>\n",
       "      <td>0.428793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.342098</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.553751</td>\n",
       "      <td>0.604719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aluminum</th>\n",
       "      <td>0.432154</td>\n",
       "      <td>0.423102</td>\n",
       "      <td>0.432185</td>\n",
       "      <td>0.437130</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.348393</td>\n",
       "      <td>0.375043</td>\n",
       "      <td>0.575392</td>\n",
       "      <td>0.632767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apologise</th>\n",
       "      <td>0.370660</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.594707</td>\n",
       "      <td>0.570335</td>\n",
       "      <td>0.342098</td>\n",
       "      <td>0.348393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>0.387751</td>\n",
       "      <td>0.439148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apologize</th>\n",
       "      <td>0.387622</td>\n",
       "      <td>0.389248</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>0.567112</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.375043</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406967</td>\n",
       "      <td>0.467883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armour</th>\n",
       "      <td>0.484073</td>\n",
       "      <td>0.487540</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.553751</td>\n",
       "      <td>0.575392</td>\n",
       "      <td>0.387751</td>\n",
       "      <td>0.406967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armor</th>\n",
       "      <td>0.525622</td>\n",
       "      <td>0.516287</td>\n",
       "      <td>0.498651</td>\n",
       "      <td>0.495369</td>\n",
       "      <td>0.604719</td>\n",
       "      <td>0.632767</td>\n",
       "      <td>0.439148</td>\n",
       "      <td>0.467883</td>\n",
       "      <td>0.954020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   center    centre  acknowledgement  acknowledgment  \\\n",
       "center           1.000000  0.965872         0.438927        0.432333   \n",
       "centre           0.965872  1.000000         0.451336        0.435852   \n",
       "acknowledgement  0.438927  0.451336         1.000000        0.986960   \n",
       "acknowledgment   0.432333  0.435852         0.986960        1.000000   \n",
       "aluminium        0.414315  0.420350         0.430719        0.428793   \n",
       "aluminum         0.432154  0.423102         0.432185        0.437130   \n",
       "apologise        0.370660  0.382979         0.594707        0.570335   \n",
       "apologize        0.387622  0.389248         0.588531        0.567112   \n",
       "armour           0.484073  0.487540         0.443998        0.442713   \n",
       "armor            0.525622  0.516287         0.498651        0.495369   \n",
       "\n",
       "                 aluminium  aluminum  apologise  apologize    armour     armor  \n",
       "center            0.414315  0.432154   0.370660   0.387622  0.484073  0.525622  \n",
       "centre            0.420350  0.423102   0.382979   0.389248  0.487540  0.516287  \n",
       "acknowledgement   0.430719  0.432185   0.594707   0.588531  0.443998  0.498650  \n",
       "acknowledgment    0.428793  0.437130   0.570335   0.567112  0.442713  0.495369  \n",
       "aluminium         1.000000  0.982919   0.342098   0.358222  0.553751  0.604719  \n",
       "aluminum          0.982919  1.000000   0.348393   0.375043  0.575392  0.632767  \n",
       "apologise         0.342098  0.348393   1.000000   0.979176  0.387751  0.439148  \n",
       "apologize         0.358222  0.375043   0.979176   1.000000  0.406967  0.467883  \n",
       "armour            0.553751  0.575392   0.387751   0.406967  1.000000  0.954020  \n",
       "armor             0.604719  0.632767   0.439148   0.467883  0.954020  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"center\",\n",
    "    \"centre\",\n",
    "    \"acknowledgement\",\n",
    "    \"acknowledgment\",\n",
    "    \"aluminium\",\n",
    "    \"aluminum\",\n",
    "    \"apologise\",\n",
    "    \"apologize\",\n",
    "    \"armour\",\n",
    "    \"armor\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "\n",
    "df = pd.DataFrame(data=similarities, index=sentences, columns=sentences)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad81f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870: acknowledgement and acknowledgment\n",
      "0.9829: aluminium and aluminum\n",
      "0.9792: apologise and apologize\n",
      "0.9659: center and centre\n",
      "0.9540: armour and armor\n",
      "0.6328: aluminum and armor\n",
      "0.6047: aluminium and armor\n",
      "0.5947: acknowledgement and apologise\n",
      "0.5885: acknowledgement and apologize\n",
      "0.5754: aluminum and armour\n"
     ]
    }
   ],
   "source": [
    "paraphrases = paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[:10]:\n",
    "    score, i, j = paraphrase\n",
    "    print(f\"{score:.4f}: {sentences[i]} and {sentences[j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35715832",
   "metadata": {},
   "source": [
    "let's explore the oxford 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f06b010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'an',\n",
       " 'abandon',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'academic',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accompany',\n",
       " 'according to',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'accuse',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acknowledge',\n",
       " 'acquire',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'administration',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'all right',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'always',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'ambition',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'ankle',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apologize',\n",
       " 'app',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approximately',\n",
       " 'April',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arise',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrest',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'as',\n",
       " 'ashamed',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'at',\n",
       " 'athlete',\n",
       " 'atmosphere',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'audience',\n",
       " 'August',\n",
       " 'aunt',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backward',\n",
       " 'bacteria',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bake',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barrier',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'bend',\n",
       " 'benefit',\n",
       " 'bent',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billion',\n",
       " 'biology',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'boil',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'bride',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'bubble',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bullet',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'businessman',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butter',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'cable',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'calculate',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'camping',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cap',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'captain',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'careless',\n",
       " 'carpet',\n",
       " 'carrot',\n",
       " 'carry',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'category',\n",
       " 'cause',\n",
       " 'CD',\n",
       " 'ceiling',\n",
       " 'celebrate',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'century',\n",
       " 'ceremony',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characteristic',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'chart',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'cheerful',\n",
       " 'cheese',\n",
       " 'chef',\n",
       " 'chemical',\n",
       " 'chemistry',\n",
       " 'chest',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'chip',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'church',\n",
       " 'cigarette',\n",
       " 'circle',\n",
       " 'circumstance',\n",
       " 'cite',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'classroom',\n",
       " 'clause',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clerk',\n",
       " 'clever',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climate',\n",
       " 'climb',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closet',\n",
       " 'cloth',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'coach',\n",
       " 'coal',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coin',\n",
       " 'cold',\n",
       " 'collapse',\n",
       " 'colleague',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'column',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'comparison',\n",
       " 'compete',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'competitor',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'component',\n",
       " 'computer',\n",
       " 'concentrate',\n",
       " 'concentration',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'conclude',\n",
       " 'conclusion',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'congress',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'conscious',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'consist',\n",
       " 'consistent',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construct',\n",
       " 'construction',\n",
       " 'consume',\n",
       " 'consumer',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'container',\n",
       " 'contemporary',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continent',\n",
       " 'continue',\n",
       " 'continuous',\n",
       " 'contract',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'convert',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'cook',\n",
       " 'cookie',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costume',\n",
       " 'cotton',\n",
       " 'could',\n",
       " 'council',\n",
       " 'count',\n",
       " 'country',\n",
       " 'countryside',\n",
       " 'county',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'cow',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'creature',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'criterion',\n",
       " 'critic',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'criticize',\n",
       " 'crop',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'crucial',\n",
       " 'cruel',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cup',\n",
       " 'cupboard',\n",
       " 'cure',\n",
       " 'curly',\n",
       " 'currency',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curtain',\n",
       " 'curve',\n",
       " 'curved',\n",
       " 'custom',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cycle',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'dance',\n",
       " 'dancer',\n",
       " 'dancing',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'December',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decision',\n",
       " 'declare',\n",
       " 'decline',\n",
       " 'decorate',\n",
       " 'decoration',\n",
       " 'decrease',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defend',\n",
       " 'defense',\n",
       " 'define',\n",
       " 'definite',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'delicious',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'demonstrate',\n",
       " 'dentist',\n",
       " 'deny',\n",
       " 'department',\n",
       " 'departure',\n",
       " 'depend',\n",
       " 'depressed',\n",
       " 'depressing',\n",
       " 'depth',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'desert',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'designer',\n",
       " 'desire',\n",
       " 'desk',\n",
       " 'desperate',\n",
       " 'despite',\n",
       " 'dessert',\n",
       " 'destination',\n",
       " 'destroy',\n",
       " 'detail',\n",
       " 'detailed',\n",
       " 'detect',\n",
       " 'detective',\n",
       " 'determine',\n",
       " 'determined',\n",
       " 'develop',\n",
       " 'development',\n",
       " 'device',\n",
       " 'diagram',\n",
       " 'dialogue',\n",
       " 'diamond',\n",
       " 'diary',\n",
       " 'dictionary',\n",
       " 'die',\n",
       " 'diet',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'differently',\n",
       " 'difficult',\n",
       " 'difficulty',\n",
       " 'dig',\n",
       " 'digital',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'disadvantage',\n",
       " 'disagree',\n",
       " 'disappear',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disaster',\n",
       " 'discipline',\n",
       " 'discount',\n",
       " 'discover',\n",
       " 'discovery',\n",
       " 'discuss',\n",
       " 'discussion',\n",
       " 'disease',\n",
       " 'dish',\n",
       " 'dishonest',\n",
       " 'disk',\n",
       " 'dislike',\n",
       " 'dismiss',\n",
       " 'display',\n",
       " 'distance',\n",
       " 'distribute',\n",
       " 'distribution',\n",
       " 'district',\n",
       " 'divide',\n",
       " 'division',\n",
       " 'divorced',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'documentary',\n",
       " 'dog',\n",
       " 'dollar',\n",
       " 'domestic',\n",
       " 'dominate',\n",
       " 'donate',\n",
       " 'door',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'down',\n",
       " 'download',\n",
       " 'downstairs',\n",
       " 'downtown',\n",
       " 'downward',\n",
       " 'dozen',\n",
       " 'draft',\n",
       " 'drag',\n",
       " 'drama',\n",
       " 'dramatic',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'dream',\n",
       " 'dress',\n",
       " 'dressed',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'drum',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'due',\n",
       " 'during',\n",
       " 'dust',\n",
       " 'duty',\n",
       " 'DVD',\n",
       " 'each',\n",
       " 'ear',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'earth',\n",
       " 'earthquake',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'economic',\n",
       " 'economy',\n",
       " 'edge',\n",
       " 'edit',\n",
       " 'edition',\n",
       " 'editor',\n",
       " 'educate',\n",
       " 'educated',\n",
       " 'education',\n",
       " 'educational',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egg',\n",
       " 'eight',\n",
       " 'eighteen',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'elderly',\n",
       " 'elect',\n",
       " 'election',\n",
       " 'electric',\n",
       " 'electrical',\n",
       " 'electricity',\n",
       " 'electronic',\n",
       " 'element',\n",
       " 'elephant',\n",
       " 'elevator',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'email',\n",
       " 'embarrassed',\n",
       " 'embarrassing',\n",
       " 'emerge',\n",
       " 'emergency',\n",
       " 'emotion',\n",
       " 'emotional',\n",
       " 'emphasis',\n",
       " 'emphasize',\n",
       " 'employ',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'employment',\n",
       " 'empty',\n",
       " 'enable',\n",
       " 'encounter',\n",
       " 'encourage',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enemy',\n",
       " 'energy',\n",
       " 'engage',\n",
       " 'engaged',\n",
       " 'engine',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'enhance',\n",
       " 'enjoy',\n",
       " 'enormous',\n",
       " 'enough',\n",
       " 'ensure',\n",
       " 'enter',\n",
       " 'entertain',\n",
       " 'entertainment',\n",
       " 'enthusiasm',\n",
       " 'enthusiastic',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entrance',\n",
       " 'entry',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'episode',\n",
       " 'equal',\n",
       " 'equally',\n",
       " 'equipment',\n",
       " 'error',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'essay',\n",
       " 'essential',\n",
       " 'establish',\n",
       " 'estate',\n",
       " 'estimate',\n",
       " 'ethical',\n",
       " 'euro',\n",
       " 'evaluate',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'evidence',\n",
       " 'evil',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'exam',\n",
       " 'examination',\n",
       " 'examine',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exchange',\n",
       " 'excited',\n",
       " 'excitement',\n",
       " 'exciting',\n",
       " 'excuse',\n",
       " 'executive',\n",
       " 'exercise',\n",
       " 'exhibit',\n",
       " 'exhibition',\n",
       " 'exist',\n",
       " 'existence',\n",
       " 'exit',\n",
       " 'expand',\n",
       " 'expect',\n",
       " 'expectation',\n",
       " 'expected',\n",
       " 'expense',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiment',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explanation',\n",
       " 'explode',\n",
       " 'exploration',\n",
       " 'explore',\n",
       " 'explosion',\n",
       " 'export',\n",
       " 'expose',\n",
       " 'express',\n",
       " 'expression',\n",
       " 'extend',\n",
       " 'extent',\n",
       " 'external',\n",
       " 'extra',\n",
       " 'extraordinary',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'facility',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factory',\n",
       " 'fail',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'faith',\n",
       " 'fall',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fancy',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'farm',\n",
       " 'farmer',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"American_Oxford_3000.txt\", \"r\") as file:\n",
    "    oxford_3000 = file.read().splitlines()\n",
    "\n",
    "oxford_3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b99e9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrases = paraphrase_mining(model, oxford_3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a938376",
   "metadata": {},
   "source": [
    "this shows us that different parts of speech are also rated as very similar, not just spelling variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583aafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819: transport and transportation\n",
      "0.9786: concern and concerned\n",
      "0.9768: dance and dancing\n",
      "0.9744: humor and humorous\n",
      "0.9741: threat and threaten\n",
      "0.9727: surprised and surprising\n",
      "0.9723: invest and investment\n",
      "0.9722: political and politics\n",
      "0.9719: laugh and laughter\n",
      "0.9717: success and successful\n",
      "0.9716: surprise and surprising\n",
      "0.9715: percent and percentage\n",
      "0.9711: exhibit and exhibition\n",
      "0.9700: embarrassed and embarrassing\n",
      "0.9698: television and TV\n",
      "0.9692: surprise and surprised\n",
      "0.9691: thank and thanks\n",
      "0.9684: feel and feeling\n",
      "0.9681: work and working\n",
      "0.9680: disappointed and disappointing\n"
     ]
    }
   ],
   "source": [
    "for paraphrase in paraphrases[:20]:\n",
    "    score, i, j = paraphrase\n",
    "    print(f\"{score:.4f}: {oxford_3000[i]} and {oxford_3000[j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a4655",
   "metadata": {},
   "source": [
    "i assume the story isn't any different with the 5000....yep, parts of speech are close to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b28f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885: disappointing and disappoint\n",
      "0.9819: transport and transportation\n",
      "0.9800: disappointed and disappoint\n",
      "0.9786: concern and concerned\n",
      "0.9775: anxiety and anxious\n",
      "0.9773: embarrassing and embarrassment\n",
      "0.9768: dance and dancing\n",
      "0.9753: agriculture and agricultural\n",
      "0.9744: donation and donate\n",
      "0.9744: humor and humorous\n",
      "0.9741: threat and threaten\n",
      "0.9727: surprising and surprised\n",
      "0.9723: investment and invest\n",
      "0.9722: political and politics\n",
      "0.9721: embarrassment and embarrassed\n",
      "0.9719: laughter and laugh\n",
      "0.9717: successful and success\n",
      "0.9716: surprising and surprise\n",
      "0.9715: percent and percentage\n",
      "0.9711: exhibit and exhibition\n"
     ]
    }
   ],
   "source": [
    "with open(\"American_Oxford_3000.txt\") as file:\n",
    "    oxford_3000 = file.read().splitlines()\n",
    "with open(\"American_Oxford_5000.txt\") as file:\n",
    "    oxford_5000 = file.read().splitlines()\n",
    "\n",
    "oxford_5000 = oxford_3000 + oxford_5000\n",
    "oxford_5000 = [word.lower() for word in oxford_5000]\n",
    "oxford_5000 = list(set(oxford_5000))\n",
    "\n",
    "paraphrases = paraphrase_mining(model, oxford_5000)\n",
    "\n",
    "for paraphrase in paraphrases[:20]:\n",
    "    score, i, j = paraphrase\n",
    "    print(f\"{score:.4f}: {oxford_5000[i]} and {oxford_5000[j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9f7ca",
   "metadata": {},
   "source": [
    "let's measure some similarities against the oxford 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678bbc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tall</th>\n",
       "      <th>short</th>\n",
       "      <th>towering</th>\n",
       "      <th>tiny</th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>cat poster</th>\n",
       "      <th>k-pop: demon hunter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reporter</th>\n",
       "      <td>0.480071</td>\n",
       "      <td>0.516974</td>\n",
       "      <td>0.448286</td>\n",
       "      <td>0.453084</td>\n",
       "      <td>0.529671</td>\n",
       "      <td>0.534547</td>\n",
       "      <td>0.338920</td>\n",
       "      <td>0.328210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.509781</td>\n",
       "      <td>0.518548</td>\n",
       "      <td>0.480742</td>\n",
       "      <td>0.538568</td>\n",
       "      <td>0.531540</td>\n",
       "      <td>0.560842</td>\n",
       "      <td>0.441819</td>\n",
       "      <td>0.313984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insertion</th>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.504075</td>\n",
       "      <td>0.514273</td>\n",
       "      <td>0.516791</td>\n",
       "      <td>0.515696</td>\n",
       "      <td>0.543627</td>\n",
       "      <td>0.374707</td>\n",
       "      <td>0.320129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lane</th>\n",
       "      <td>0.536695</td>\n",
       "      <td>0.522634</td>\n",
       "      <td>0.573151</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.587027</td>\n",
       "      <td>0.600137</td>\n",
       "      <td>0.422186</td>\n",
       "      <td>0.395254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <td>0.537972</td>\n",
       "      <td>0.532212</td>\n",
       "      <td>0.543449</td>\n",
       "      <td>0.542116</td>\n",
       "      <td>0.606398</td>\n",
       "      <td>0.620119</td>\n",
       "      <td>0.412994</td>\n",
       "      <td>0.375025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photograph</th>\n",
       "      <td>0.525835</td>\n",
       "      <td>0.524351</td>\n",
       "      <td>0.551870</td>\n",
       "      <td>0.547570</td>\n",
       "      <td>0.550596</td>\n",
       "      <td>0.574350</td>\n",
       "      <td>0.527521</td>\n",
       "      <td>0.372931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.536208</td>\n",
       "      <td>0.529321</td>\n",
       "      <td>0.522877</td>\n",
       "      <td>0.573929</td>\n",
       "      <td>0.592988</td>\n",
       "      <td>0.633246</td>\n",
       "      <td>0.434403</td>\n",
       "      <td>0.373971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dream</th>\n",
       "      <td>0.565285</td>\n",
       "      <td>0.551067</td>\n",
       "      <td>0.554877</td>\n",
       "      <td>0.590610</td>\n",
       "      <td>0.589437</td>\n",
       "      <td>0.587224</td>\n",
       "      <td>0.457107</td>\n",
       "      <td>0.417472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confess</th>\n",
       "      <td>0.401994</td>\n",
       "      <td>0.468296</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>0.483429</td>\n",
       "      <td>0.520968</td>\n",
       "      <td>0.516197</td>\n",
       "      <td>0.406570</td>\n",
       "      <td>0.349524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daughter</th>\n",
       "      <td>0.529715</td>\n",
       "      <td>0.482732</td>\n",
       "      <td>0.481559</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.509169</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>0.378688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4323 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tall     short  towering      tiny  baseball  basketball  \\\n",
       "reporter    0.480071  0.516974  0.448286  0.453084  0.529671    0.534547   \n",
       "medium      0.509781  0.518548  0.480742  0.538568  0.531540    0.560842   \n",
       "insertion   0.476257  0.504075  0.514273  0.516791  0.515696    0.543627   \n",
       "lane        0.536695  0.522634  0.573151  0.565615  0.587027    0.600137   \n",
       "ever        0.537972  0.532212  0.543449  0.542116  0.606398    0.620119   \n",
       "...              ...       ...       ...       ...       ...         ...   \n",
       "photograph  0.525835  0.524351  0.551870  0.547570  0.550596    0.574350   \n",
       "mercy       0.536208  0.529321  0.522877  0.573929  0.592988    0.633246   \n",
       "dream       0.565285  0.551067  0.554877  0.590610  0.589437    0.587224   \n",
       "confess     0.401994  0.468296  0.446281  0.483429  0.520968    0.516197   \n",
       "daughter    0.529715  0.482732  0.481559  0.487667  0.509169    0.520679   \n",
       "\n",
       "            cat poster  k-pop: demon hunter  \n",
       "reporter      0.338920             0.328210  \n",
       "medium        0.441819             0.313984  \n",
       "insertion     0.374707             0.320129  \n",
       "lane          0.422186             0.395254  \n",
       "ever          0.412994             0.375025  \n",
       "...                ...                  ...  \n",
       "photograph    0.527521             0.372931  \n",
       "mercy         0.434403             0.373971  \n",
       "dream         0.457107             0.417472  \n",
       "confess       0.406570             0.349524  \n",
       "daughter      0.393217             0.378688  \n",
       "\n",
       "[4323 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"tall\",\n",
    "    \"short\",\n",
    "    \"towering\",\n",
    "    \"tiny\",\n",
    "    \"baseball\",\n",
    "    \"basketball\",\n",
    "    \"cat poster\",\n",
    "    \"k-pop: demon hunter\"\n",
    "]\n",
    "\n",
    "sentences_embeddings = model.encode(sentences)\n",
    "oxford_5000_embeddings = model.encode(oxford_5000)\n",
    "similarities = model.similarity(oxford_5000_embeddings, sentences_embeddings)\n",
    "\n",
    "df = pd.DataFrame(data=similarities, index=oxford_5000, columns=sentences)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f53fa632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tall</th>\n",
       "      <th>short</th>\n",
       "      <th>towering</th>\n",
       "      <th>tiny</th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>cat poster</th>\n",
       "      <th>k-pop: demon hunter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demon</th>\n",
       "      <td>0.508911</td>\n",
       "      <td>0.532366</td>\n",
       "      <td>0.568567</td>\n",
       "      <td>0.537796</td>\n",
       "      <td>0.582338</td>\n",
       "      <td>0.590081</td>\n",
       "      <td>0.449394</td>\n",
       "      <td>0.600794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singer</th>\n",
       "      <td>0.519338</td>\n",
       "      <td>0.489772</td>\n",
       "      <td>0.476585</td>\n",
       "      <td>0.492340</td>\n",
       "      <td>0.558919</td>\n",
       "      <td>0.538812</td>\n",
       "      <td>0.406942</td>\n",
       "      <td>0.554147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devil</th>\n",
       "      <td>0.505224</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.558270</td>\n",
       "      <td>0.544426</td>\n",
       "      <td>0.606784</td>\n",
       "      <td>0.603446</td>\n",
       "      <td>0.428363</td>\n",
       "      <td>0.543682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hunt</th>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.537045</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.594950</td>\n",
       "      <td>0.620769</td>\n",
       "      <td>0.484303</td>\n",
       "      <td>0.534947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>0.498248</td>\n",
       "      <td>0.524418</td>\n",
       "      <td>0.496971</td>\n",
       "      <td>0.523291</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.540647</td>\n",
       "      <td>0.383907</td>\n",
       "      <td>0.526658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.488081</td>\n",
       "      <td>0.503320</td>\n",
       "      <td>0.478741</td>\n",
       "      <td>0.532498</td>\n",
       "      <td>0.579212</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.516504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>0.455482</td>\n",
       "      <td>0.471986</td>\n",
       "      <td>0.490233</td>\n",
       "      <td>0.512559</td>\n",
       "      <td>0.521811</td>\n",
       "      <td>0.538571</td>\n",
       "      <td>0.443407</td>\n",
       "      <td>0.508152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chase</th>\n",
       "      <td>0.505847</td>\n",
       "      <td>0.521947</td>\n",
       "      <td>0.567516</td>\n",
       "      <td>0.543573</td>\n",
       "      <td>0.583834</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.505885</td>\n",
       "      <td>0.502636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancer</th>\n",
       "      <td>0.600887</td>\n",
       "      <td>0.560551</td>\n",
       "      <td>0.567870</td>\n",
       "      <td>0.545687</td>\n",
       "      <td>0.558464</td>\n",
       "      <td>0.635308</td>\n",
       "      <td>0.454879</td>\n",
       "      <td>0.502603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monster</th>\n",
       "      <td>0.555564</td>\n",
       "      <td>0.540075</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>0.559371</td>\n",
       "      <td>0.621170</td>\n",
       "      <td>0.619114</td>\n",
       "      <td>0.456530</td>\n",
       "      <td>0.501834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tall     short  towering      tiny  baseball  basketball  \\\n",
       "demon    0.508911  0.532366  0.568567  0.537796  0.582338    0.590081   \n",
       "singer   0.519338  0.489772  0.476585  0.492340  0.558919    0.538812   \n",
       "devil    0.505224  0.513279  0.558270  0.544426  0.606784    0.603446   \n",
       "hunt     0.555002  0.537045  0.534461  0.555091  0.594950    0.620769   \n",
       "song     0.498248  0.524418  0.496971  0.523291  0.558800    0.540647   \n",
       "music    0.488081  0.503320  0.478741  0.532498  0.579212    0.576172   \n",
       "pop      0.455482  0.471986  0.490233  0.512559  0.521811    0.538571   \n",
       "chase    0.505847  0.521947  0.567516  0.543573  0.583834    0.608333   \n",
       "dancer   0.600887  0.560551  0.567870  0.545687  0.558464    0.635308   \n",
       "monster  0.555564  0.540075  0.603281  0.559371  0.621170    0.619114   \n",
       "\n",
       "         cat poster  k-pop: demon hunter  \n",
       "demon      0.449394             0.600794  \n",
       "singer     0.406942             0.554147  \n",
       "devil      0.428363             0.543682  \n",
       "hunt       0.484303             0.534947  \n",
       "song       0.383907             0.526658  \n",
       "music      0.412197             0.516504  \n",
       "pop        0.443407             0.508152  \n",
       "chase      0.505885             0.502636  \n",
       "dancer     0.454879             0.502603  \n",
       "monster    0.456530             0.501834  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"k-pop: demon hunter\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9714dc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demon            0.600794\n",
       "singer           0.554147\n",
       "devil            0.543682\n",
       "hunt             0.534947\n",
       "song             0.526658\n",
       "music            0.516504\n",
       "pop              0.508152\n",
       "chase            0.502636\n",
       "dancer           0.502603\n",
       "monster          0.501834\n",
       "haunt            0.494987\n",
       "predator         0.490669\n",
       "fantasy          0.489724\n",
       "fan              0.485427\n",
       "defender         0.481781\n",
       "musician         0.480738\n",
       "hunting          0.479617\n",
       "genre            0.479289\n",
       "boy              0.476963\n",
       "monk             0.474900\n",
       "ghost            0.474322\n",
       "lyric            0.473135\n",
       "entertainment    0.472714\n",
       "among            0.472252\n",
       "beast            0.471684\n",
       "Name: k-pop: demon hunter, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['k-pop: demon hunter'].sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4df6af",
   "metadata": {},
   "source": [
    "try the csv version, so we can filter by part of speech and level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
